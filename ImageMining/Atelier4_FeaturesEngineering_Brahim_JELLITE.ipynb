{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brahimje/DataMining/blob/main/ImageMining/Atelier4_FeaturesEngineering_Brahim_JELLITE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5enhfiSt2VLx"
      },
      "source": [
        "<center> <h1>Ing√©nierie des caract√©ristiques <br> (Features engineering)</h1></center>\n",
        "\n",
        "Pour regarder la vid√©o du support de cours:\n",
        "https://youtu.be/OTEhvJhismM\n",
        "\n",
        "A la fin, il faut remplir le formulaire ci-dessous utilisant les donn√©es de votre impl√©mentation\n",
        "\n",
        "https://forms.gle/1jmXku2ftAehbceRA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0ZZ2Hwdzez3"
      },
      "source": [
        "<h1> Plan </h1>\n",
        "\n",
        "*\tIntroduction\n",
        "*\tNormalisation des caract√©ristiques\n",
        "*\tS√©lection des caract√©ristiques\n",
        "   -\tR√©duction\n",
        "   -  S√©lection\n",
        "*\tImpl√©mentation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNs-cVLa0Y3S"
      },
      "source": [
        "<h1> Introduction </h1>\n",
        "Concevoir un mod√®le de classification performant repose sur plusieurs facteurs:\n",
        "\n",
        "* Type et coh√©rence de la base donn√©es (base de donn√©es √©quilibr√©es)\n",
        "* Choix des caract√©ristiques pertinentes\n",
        "* Choix d‚Äôun algorithme de classification judicieux\n",
        "\n",
        "D‚Äôapr√®s les experts dans le domaine:\n",
        "\n",
        "* Les caract√©ristiques √† utiliser en classification influencent plus que tout autre param√®tre sur le r√©sultat. \n",
        "* Aucun algorithme ne peut remplacer √† lui seul le suppl√©ment que les caract√©ristiques procurent\n",
        "\n",
        "Selon une enqu√™te de Forbes (2016), les datascientists  consacrent 80 % (19% collection; 60% nettoyage et organisation) de leur temps √† la pr√©paration des donn√©es. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA-qglwY03HC"
      },
      "source": [
        "<h1>Ing√©nierie de caract√©ristiques</h1>\n",
        "L'Ing√©nierie de caract√©ristiques consiste en le traitement des caract√©ristiques dans le but d'am√©liorer le comportement du mod√©le de classification. <br>\n",
        "Plusieurs √©tapes peuvent √™tre utilis√©es (pas toutes utilisables pour l‚Äôimage mining) \n",
        "\n",
        "* Valeurs manquantes (Non rencotr√©s en Image Mining)\n",
        "* Valeurs aberrantes\n",
        "* Transformation logarithmique\n",
        "* Encodage unique (Concerne uniquement les √©tiquettes en Image Mining)\n",
        "* Mise en √©chelle\n",
        "* S√©lection des caract√©ristiques\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6fblqPN1-VW"
      },
      "source": [
        "<h1> Impl√©mentation </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh7Maj0p2PHo"
      },
      "source": [
        "<h2> Pr√©paration de l'environnement</h2>\n",
        "Nous allons travailler dans cet atelier sur des caract√©ristiques d√©ja extraites et enregistr√©es sur Google Drive  (Voir atelier tranfer Learning)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az36GUAH63ZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80a2dc15-7436-4499-f6ac-5b504b918e0d"
      },
      "source": [
        "#from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZKCruVyWOig"
      },
      "source": [
        "<h2> Chargement de la dataset</h2>\n",
        "Pour tester et appliquer l'ing√©nierie de caract√©ristiques, nous allons utiliser des caract√©ristiques d√©j√† extraites utilisant une architecture Deep Learning VGG16 de la base d'image Corel utilis√©e dans l'atelier de classification supervis√©e. \n",
        "Pour t√©l√©charger le fichier de caract√©ristiques et les √©tiquettes cliquer sur les liens ci-dessous :\n",
        "\n",
        "[Features](https://drive.google.com/file/d/105zEqcYD1Deuzy5NM5dOPqnXDETUAfVt/view?usp=share_link)\n",
        "\n",
        "\n",
        "[Labels](https://drive.google.com/file/d/1aggw9QXm9ao7CEmLa4ign9xi2zovUPnB/view?usp=drivesdk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlrbCdv5216j"
      },
      "source": [
        "Vous pouvez utiliser le m√™me chemin que celui que j'ai utilis√© :\n",
        "/content/drive/MyDrive/FeaturesEngineering/\n",
        "- Cr√©er un dossier sur la racine de votre drive \"MyDrive\" et nomm√© le: \"FeaturesEngineering\"\n",
        "- Copier les fichiers \"features_vgg16\" et \"labels\" dans le dossier \"FeaturesEngineering\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Charger les caract√©ristiques et les √©tiquettes.</h3>"
      ],
      "metadata": {
        "id": "sDSBKCVrxuCp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Mocd_cxfmnF",
        "outputId": "ff16226d-8327-4b53-8d3c-351b203b867b"
      },
      "source": [
        "# Load features and labels\n",
        "import pickle\n",
        "fetauresPath='/content/drive/MyDrive/FeaturesEngineering/'\n",
        "X = pickle.load( open( fetauresPath+\"features_vgg16\", \"rb\" ) )\n",
        "y =pickle.load( open( fetauresPath+\"labels\", \"rb\" ) )\n",
        "\n",
        "import numpy as np\n",
        "print(np.array(X).shape, np.array(y).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(490, 1000) (490,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQR4kVA93NJz"
      },
      "source": [
        "Pour chacune des √©tapes de l'ing√©nierie de caract√©ristiques, nous allons √©valuer √† chaque fois la classification afin de voir l'impact. \n",
        "Compl√©ter l'impl√©mentation de la fonction de classification. Utiliser un algorithme de classification de votre choix. \n",
        "La m√©thode doit afficher le taux de classification (accuracy) ainsi que le temps d'ex√©cution de classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8te-Q8eUcKZA"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "\n",
        "def classify(X,y):\n",
        "  # Compl√©ter le code\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "  clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  \n",
        "  accuracy = clf.score(X_test, y_test)\n",
        "  print(\"Accuracy:\", accuracy)\n",
        "  scores = cross_val_score(clf, X, y, cv=5)\n",
        "\n",
        "  # affichez les scores de chaque it√©ration de la validation crois√©e\n",
        "  print(\"Cross validation scores:\", scores)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13dK8hRi4PY0"
      },
      "source": [
        "Classification utilisant les caract√©ristiques initiales sans manipulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDSvx4pV4Oal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67401d5e-046c-4d18-9d7c-ad1f249aaf84"
      },
      "source": [
        "# Afficher l'accuracy\n",
        "classify(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9489795918367347\n",
            "Cross validation scores: [0.96938776 0.97959184 0.98979592 0.97959184 0.94897959]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DM0ri2E4CUQ"
      },
      "source": [
        "<h1>Mise en √©chelle</h1>\n",
        "Dans la plupart des cas, les caract√©ristiques de type num√©rique ne sont pas dans la m√™me plage d‚Äôintervalle.\n",
        "Exemple : les donn√©es sur les √¢ges et les salaires diff√©rent et ne n‚Äôont pas la m√™me fourchette.\n",
        "Pour un algorithme d‚Äôapprentissage automatique, les valeurs qui ne changent pas beaucoup m√™me sur diff√©rentes √©chelles vont √™tre tr√®s influentes en termes de classification.\n",
        "Les algorithmes de classification bas√©s sur le voisinage ou distance sont tr√®s sensible √† la mise en √©chelle ; comme le KNN, K-means, ‚Ä¶\n",
        "Pour mettre en √©chelle les donn√©es nous avons deux solutions :\n",
        "\n",
        "1.   Normalisation : min-max normalization\n",
        "2.   Standardisation : z-score normalization\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGMAS9qf7cAk"
      },
      "source": [
        "<h2> Standarization: z-score normalization</h2>\n",
        "<center>z=(X-¬µ)/œÉ\n",
        "\n",
        "X est l'ensemble d'apprentissage, ¬µ est la moyenne et  œÉ est l‚Äô√©cart type\n",
        "</center>\n",
        "Le z-score met en √©chelle les valeurs en prenant en compte l‚Äô√©cart type (d√©viation standard). <br> \n",
        "le z-score r√©duit l‚Äôeffet des donn√©es aberrantes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmxT5qUn4AqY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "671be80b-8a6c-45d8-bff5-5c02fee553dc"
      },
      "source": [
        "\"\"\"Standarization\n",
        "Standardize features by removing the mean and scaling to unit variance.\n",
        "z = (x - u) / s\n",
        "where u is the mean of the training samples or zero if with_mean=False\n",
        "s is the standard deviation of the training samples or one if with_std=False.\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "def standardize(X):\n",
        "    # Calculate the mean and standard deviation of the input data\n",
        "    mean = np.mean(X, axis=0)\n",
        "    std = np.std(X, axis=0)\n",
        "\n",
        "    # Standardize the data by subtracting the mean and dividing by the standard deviation\n",
        "    z = (X - mean) / std\n",
        "    return z\n",
        "\n",
        "# Xzscore est la matrice de caract√©ristiques apr√®s standardisation\n",
        "Xzscore = standardize(X)\n",
        "#print(np.array(Xzscore).shape)\n",
        "classify(Xzscore,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9387755102040817\n",
            "Cross validation scores: [0.98979592 0.96938776 0.98979592 0.94897959 0.93877551]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR_TAfUF8fEm"
      },
      "source": [
        "<h2>Normalization: min-max normalization</h2>\n",
        "<center>Xnorm=(X-Xmin)/(Xmax -Xmin)</center>\n",
        "Permet de mettre en √©chelle toutes les valeurs des caract√©ristiques dans une plage fixe entre 0 et 1.<br>\n",
        "L'inconv√©nient de la normalization par min-max est qu'elle augmente les effets des valeurs aberrantes.<br>\n",
        "Ainsi, avant la normalisation, il est recommand√© de traiter les valeurs aberrantes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtDmpKJT9TaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a48af9a4-20b3-461d-d8da-16b9bef73d16"
      },
      "source": [
        "\"\"\"Noramlization\n",
        "Xnorm=(X-Xmin)/(Xmax -Xmin).\n",
        "\"\"\"\n",
        "def normalize(X):\n",
        "    # Calculate the minimum and maximum values of the input data\n",
        "    Xmin = np.min(X, axis=0)\n",
        "    Xmax = np.max(X, axis=0)\n",
        "\n",
        "    # Normalize the data by subtracting the minimum value and dividing by the range\n",
        "    Xnorm = (X - Xmin) / (Xmax - Xmin)\n",
        "\n",
        "    return Xnorm\n",
        "\n",
        "# Xminmax est la matrice de caract√©ristiques apr√®s normalisation\n",
        "Xminmax = normalize(X)\n",
        "\n",
        "#print(np.array(Xminmax).shape)\n",
        "classify(Xminmax,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9285714285714286\n",
            "Cross validation scores: [0.96938776 0.96938776 0.96938776 0.97959184 0.95918367]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvSAQajiRpSD"
      },
      "source": [
        "<h2> Transformation logarithmique</h2>\n",
        "Pour √©liminer les donn√©es aberrantes, une des techniques les plus utilis√©es est la transformation logarithmique.\n",
        "\n",
        "*\tTraiter des donn√©es biais√©es et, apr√®s transformation, la distribution devient plus proche de la normale.\n",
        "*\tR√©duire l‚Äôordre de grandeur des donn√©es. Exemple : la diff√©rence de taille n‚Äôest pas de la m√™me grandeur que la diff√©rence d'√¢ges\n",
        "*\tR√©duit aussi l'effet des valeurs aberrantes gr√¢ce √† la normalisation des diff√©rences d'amplitude\n",
        "\n",
        "NB : il ne faut pas que les donn√©es soient n√©gatives\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzaegQ7dS-b_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "184ac612-05c7-4363-eda9-3d1a8c8a54cc"
      },
      "source": [
        "# Transformation logarithmique\n",
        "# Xlog est la matrice de caract√©ristiques apr√®s transformation logarithmique\n",
        "Xlog= np.log(X)\n",
        "# Classification utilisant les caract√©ristiques apr√©s tranformation logarithmique\n",
        "classify(Xlog,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9795918367346939\n",
            "Cross validation scores: [1.         0.98979592 0.98979592 0.98979592 1.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Par la suite nous allons proc√©der a la mise en √©chelle des donn√©es apr√®s transformation logarithmique"
      ],
      "metadata": {
        "id": "jTnv_Uuqru_7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_tnub6sBz5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "178f1bc8-d1dc-4b44-dd9d-c9e014a488d9"
      },
      "source": [
        "# Normalization apr√©s TL\n",
        "def normalize_after_log_transform(X):\n",
        "    # Apply the logarithmic transformation to each element in the input data\n",
        "    X_transformed = np.log(X)\n",
        "\n",
        "    # Calculate the minimum and maximum values of the transformed data\n",
        "    Xmin = np.min(X_transformed, axis=0)\n",
        "    Xmax = np.max(X_transformed, axis=0)\n",
        "\n",
        "    # Normalize the transformed data by subtracting the minimum value and dividing by the range\n",
        "    Xnorm = (X_transformed - Xmin) / (Xmax - Xmin)\n",
        "\n",
        "    return Xnorm\n",
        "\n",
        "Xminmax_Log = normalize_after_log_transform(X)\n",
        "\n",
        "classify(Xminmax_Log,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9795918367346939\n",
            "Cross validation scores: [1.         0.98979592 0.98979592 0.98979592 1.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GF77nX0Sz1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e19530-0aa0-4e73-d8de-39f3a56cf7f0"
      },
      "source": [
        "# Standarization + TL\n",
        "def standardize_and_log_transform(X):\n",
        "    X_transformed = np.log(X)\n",
        "    X_standardized = standardize(X)\n",
        "    return X_standardized\n",
        "\n",
        "Xzscore_Log = standardize_and_log_transform(X)\n",
        "classify(Xzscore_Log,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9387755102040817\n",
            "Cross validation scores: [0.98979592 0.96938776 0.98979592 0.94897959 0.93877551]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzEa3D0hvgho"
      },
      "source": [
        "<h1>S√©lection de caract√©ristiques (features selection)</h1>\n",
        "La s√©lection de caract√©ristiques (features selection) est l‚Äôop√©ration permettant de d‚Äôextraire intelligemment de la connaissance √† partir des donn√©es brutes. \n",
        "\n",
        "Objectif:\n",
        "* Am√©liorer les performances (en termes de rapidit√©, de puissance de pr√©diction et de la simplicit√© du mod√®le).\n",
        "* R√©duire les dimensions et √©liminer le bruit. \n",
        "\n",
        "La s√©lection des caract√©ristiques est un processus qui choisit un sous-ensemble optimal de caract√©ristique en fonction d'un crit√®re donn√©.\n",
        "\n",
        "Objectif de FS: <br>\n",
        "* Supprimer les donn√©es non pertinentes,\n",
        "* Augmenter de la pr√©cision du mod√®le d‚Äôapprentissage notamment en r√©duisant les besoins en stockage et les co√ªts de calcul,\n",
        "* R√©duire le nombre de donn√©es,\n",
        "* R√©duire la complexit√© de la description du mod√®le r√©sultant,\n",
        "* Am√©liorer la compr√©hension des donn√©es et du mod√®le.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCfHsnNdF2vG"
      },
      "source": [
        "<h2>Les cat√©gories de la s√©lection des caract√©ristiques</h2>\n",
        "Trois approches sont g√©n√©ralement utilis√©es dans la s√©lection des caract√©ristiques : embedded, wrapper et filter: <br>\n",
        "\n",
        "* Les m√©thodes ¬´ embedded ¬ª int√®grent directement la s√©lection dans le processus d‚Äôapprentissage. Les arbres de d√©cision est une illustration de ce syst√®me. \n",
        "* Les m√©thodes ¬´ wrapper ¬ª optimisent explicitement un crit√®re de pr√©cision, le plus souvent le taux d‚Äôerreur. Elles ne s‚Äôappuient en rien sur les caract√©ristiques de l‚Äôalgorithme d‚Äôapprentissage qui est utilis√© comme une bo√Æte noire.\n",
        "* les m√©thodes ¬´ filter ¬ª agissent en amont, avant la mise en ≈ìuvre de la technique d‚Äôapprentissage, et sans lien direct avec celui‚Äêci.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnUqnVBhytSl"
      },
      "source": [
        "<h2> Suppression des caract√©ristiques √† faible variance</h2>\n",
        "Suppression des caract√©ristiques √† faible variance (Removing features with low variance) est une m√©thode de s√©lection (√©limination) bas√©e sur le filtrage.<br>\n",
        "On peut la consid√©rer comme une m√©thode de nettoyage de caract√©ristique qui  √©l√©mine toutes les caract√©ristiques dont la variance n'atteint pas un certain seuil.<br>\n",
        "Par d√©faut, elle supprime toutes les caract√©ristiques √† variance nulle, c'est-√†-dire les caract√©ristiques qui ont la m√™me valeur dans tous les √©chantillons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH0iwZjCy7X8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f69342b-2603-44c6-f230-1256ee4f8030"
      },
      "source": [
        "# Nous allons utiliser les caract√©ristiques apr√®s normalisation Min-Max\n",
        "# Xvth est la matrice de caract√©ristiques apr√®s suppression des caract√©ristiques (apr√®s normalisation Min-Max)  √† faible variance\n",
        "def remove_low_variance_features(X, threshold=0.1):\n",
        "    \n",
        "    Xnorm = normalize(X)\n",
        "\n",
        "    # Calculate the variance of each feature\n",
        "    variance = np.var(Xnorm, axis=0)\n",
        "\n",
        "    # Select the features with variance above the threshold\n",
        "    X_filtered = X[:, variance > threshold]\n",
        "\n",
        "    return X_filtered\n",
        "\n",
        "Xvth = remove_low_variance_features(X, threshold=0.001)\n",
        "classify(Xvth,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9489795918367347\n",
            "Cross validation scores: [0.96938776 0.97959184 0.98979592 0.97959184 0.94897959]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgWGA_pFzams"
      },
      "source": [
        "<h2>chi2</h2>\n",
        "C‚Äôest un algorithme de s√©lection des caract√©ristiques qui appartient √† la famille des algorithmes de filtrage bas√© sur la statistique ùúí2. Cette m√©thode mesure l‚Äô√©cart √† l‚Äôind√©pendance entre une caract√©ristique et une classe. Elle commence par un niveau de signification √©lev√© pour toutes les caract√©ristiques pour la discr√©tisation et chaque caract√©ristique est tri√©e en fonction de ses valeurs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2jeNK2Izhlg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee155b00-c85e-4b19-b51c-20544288ff95"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "def select_kbest_features(X, y, k=100):\n",
        "    # Use the chi-squared test to select the k best features\n",
        "    selector = SelectKBest(chi2, k=k)\n",
        "    X_new = selector.fit_transform(X, y)\n",
        "\n",
        "    return X_new\n",
        "\n",
        "#Xchi2 est la matrice de caract√©ristiques apr√®s s√©lection de 100 caract√©ristiques utilisant chi2\n",
        "Xchi2 = select_kbest_features(X, y, k=100)\n",
        "classify(Xchi2,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9489795918367347\n",
            "Cross validation scores: [0.96938776 0.97959184 0.98979592 0.97959184 0.94897959]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEsfySe00s_Y"
      },
      "source": [
        "<h2>Recursive Feature Elimination (RFE)</h2>\n",
        "C‚Äôest une m√©thode de cartographie bas√©e sur l'id√©e √† plusieurs reprises, construire un mod√®le et choisir le meilleur ou le pire performant. Cette m√©thode qui appartient aux m√©thodes de filtrage est souvent utilis√©e comme √©tape de pr√©traitement pour les m√©thodes int√©gr√©e (souvent avec l‚Äôalgorithme de classification SVM) afin de la g√©n√©raliser √† des grandes masses de donn√©es\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D2nZnux09jD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "018b6203-1dd2-432c-92b5-9ce4d34bbde3"
      },
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC(kernel='linear')\n",
        "rfe = RFE(model, n_features_to_select = 100)\n",
        "rfe = rfe.fit(X, y)\n",
        "\n",
        "# Xrfe est la matrice de caract√©ristiques apr√®s s√©lection de 100 caract√©ristiques utilisant RFE\n",
        "Xrfel = rfe.transform(X)\n",
        "classify(Xrfel,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9489795918367347\n",
            "Cross validation scores: [0.96938776 0.97959184 0.98979592 0.97959184 0.94897959]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BygazAk9mo_C"
      },
      "source": [
        "Essayer d'identifier le nombre minimal de caract√©ristiques √† utiliser pour obtenir le taux maximal de classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-IqzWEcjpFq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c88b0338-13b3-40d4-fe83-4d468cdefb61"
      },
      "source": [
        "# Code pour calculer le nombre minimal de caract√©ristiques √† utiliser pour obtenir le taux maximal de classification\n",
        "ranking = rfe.ranking_\n",
        "\n",
        "max_score = 0\n",
        "best_num_features = 0\n",
        "for num_features in range(1, len(ranking) + 1):\n",
        "    # Select the top-ranked features\n",
        "    mask = ranking <= num_features\n",
        "    X_selected = X[:, mask]\n",
        "\n",
        "    # Evaluate the classification rate using cross-validation\n",
        "    scores = cross_val_score(SVC(kernel='linear'), X_selected, y, cv=5)\n",
        "    score = np.mean(scores)\n",
        "\n",
        "    # Update the maximum score and the number of features that gave the maximum score\n",
        "    if score > max_score:\n",
        "        max_score = score\n",
        "        best_num_features = num_features\n",
        "\n",
        "print('The maximum classification rate is', max_score)\n",
        "print('It is achieved with', best_num_features, 'features')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum classification rate is 0.9734693877551021\n",
            "It is achieved with 1 features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlfaMjkGhMNM"
      },
      "source": [
        "<h1>Relief</h1>\n",
        "Tente de d√©terminer le plus proche voisin d'un certain nombre d'√©chantillons s√©lectionn√©s au hasard √† partir de l'ensemble de donn√©es. Pour chaque √©chantillon s√©lectionn√©, les valeurs des caract√©ristiques sont compar√©es √† ceux des voisins les plus proches et les scores pour chaque caract√©ristique sont mis √† jour. L'id√©e est d'estimer la qualit√© des attributs en fonction de la qualit√© de leurs valeurs et faire la distinction entre des √©chantillons proches les uns des autres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOUjTkg5jjHv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "624ef13b-9080-43b1-93bc-a94e6bc6daaf"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "\n",
        "selector = SelectKBest(mutual_info_classif, k=100)\n",
        "X_new = selector.fit_transform(X, y)\n",
        "\n",
        "# XRelief est la matrice de caract√©ristiques apr√®s s√©lection de 100 caract√©ristiques utilisant Relief\n",
        "XRelief= X_new\n",
        "classify(XRelief,y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9387755102040817\n",
            "Cross validation scores: [0.96938776 0.97959184 0.98979592 0.97959184 0.94897959]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JURQ4cvq7-s6"
      },
      "source": [
        "Essayer d'identifier le nombre minimal de caract√©ristiques √† utiliser pour obtenir le taux maximal de classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xJR__tO7-s_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c26491ee-b62b-49dd-e9c9-cbfb19209b04"
      },
      "source": [
        "# Code pour calculer le nombre minimal de caract√©ristiques √† utiliser pour obtenir le taux maximal de classification\n",
        "ranking = selector.scores_\n",
        "max_score = 0\n",
        "best_num_features = 0\n",
        "for num_features in range(1, len(ranking) + 1):\n",
        "    # Select the top-ranked features\n",
        "    mask = ranking <= num_features\n",
        "    X_selected = X[:, mask]\n",
        "\n",
        "    # Evaluate the classification rate using cross-validation\n",
        "    scores = cross_val_score(SVC(kernel='linear'), X_selected, y, cv=5)\n",
        "    score = np.mean(scores)\n",
        "\n",
        "    # Update the maximum score and the number of features that gave the maximum score\n",
        "    if score > max_score:\n",
        "        max_score = score\n",
        "        best_num_features = num_features\n",
        "\n",
        "print('The maximum classification rate is', max_score)\n",
        "print('It is achieved with', best_num_features, 'features')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum classification rate is 0.9734693877551021\n",
            "It is achieved with 1 features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85yhbzTsfwDj"
      },
      "source": [
        "<h1>R√©duction de la dimensionnalit√© </h1>\n",
        "La r√©duction de la dimensionnalit√© transforme les caract√©ristiques en une dimension inf√©rieure. Elle peut √™tre consid√©r√©e comme √©tant une m√©thode de  Selection ou de cr√©ation (extraction) de caract√©ristiques o√π nous d√©rivons des informations √† partir de l‚Äôensemble de caract√©ristiques de base pour construire un nouveau sous espace de caract√©ristiques. <br>\n",
        "Ls approches de r√©duction de dimensionnalit√© les plus connues sont: PCA (Principal Component Analysis; Analyse en Composantes Principales (ACP)) et ICA (Independent Component Analysis, Analyse en Composantes Independantes (ACI)) \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCqFtKhxl5v7"
      },
      "source": [
        "<h2> ACP </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u1-zsXzviSj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7dc6ff7-9ee5-4e14-a626-e3d3ea085093"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=100)\n",
        "\n",
        "# Xpca est la matrice de caract√©ristiques apr√®s r√©duction de la dimensionalit√© utilisant l'ACP\n",
        "# Essayer de changer la taille de r√©duction de l'ACP afin d'obtenir le meilleur taux de classification\n",
        "Xpca=pca.fit_transform(X)\n",
        "print(np.array(Xpca).shape)\n",
        "classify(Xpca,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(490, 100)\n",
            "Accuracy: 0.9489795918367347\n",
            "Cross validation scores: [0.96938776 0.97959184 0.98979592 0.97959184 0.94897959]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dehxuzuHl9Jo"
      },
      "source": [
        "<h2> ACI </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNw7JwD0mCoJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a8dbf6b-d023-4814-c130-686d5b915f05"
      },
      "source": [
        "from sklearn.decomposition import FastICA\n",
        "ica = FastICA(n_components=300)\n",
        "\n",
        "# Xica est la matrice de caract√©ristiques apr√®s r√©duction de la dimensionalit√© utilisant l'ACI\n",
        "# Essayer de changer la taille de r√©duction de l'ACI afin d'obtenir le meilleur taux de classification\n",
        "Xica = ica.fit_transform(X)\n",
        "print(np.array(Xica).shape)\n",
        "classify(Xica,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(490, 300)\n",
            "Accuracy: 0.7653061224489796\n",
            "Cross validation scores: [0.85714286 0.82653061 0.82653061 0.83673469 0.83673469]\n"
          ]
        }
      ]
    }
  ]
}